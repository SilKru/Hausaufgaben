---
title: "4. Session - Hausaufgabe - Silvia Kruse"
output:
  html_document:
    df_print: paged
---

# Libraries und Daten
```{r}
library(tidyverse)
library(e1071)
library(caret)
library(pROC)
```

```{r}
titanic <- read_delim("titanic.csv", ";", 
    escape_double = FALSE, trim_ws = TRUE)
```

Hausaufgabe: 

1. Bitte erstellen Sie ein Notebook mit weiteren Features

Als weiteres Feature habe ich neben der Klasse, dem Alter und dem Geschlecht den Einstiegsort (embarked) gewählt. Dieser Faktor schien mir von den übrig gebliebenen am plausibelsten für die "Überlebend-Berechnung" zu sein. 

Die AUC-Berechnung im unteren Beispiel mit der Beispielzahl "137" hat einen recht guten Wert von 0,855: 

```{r}
(titanic.neu <- titanic %>%
  mutate(sex = ifelse(sex == "female", 1, 0))%>%
  mutate(embarked = ifelse(embarked == "S", 0, ifelse(embarked== "C", 1, 2)))%>% 
   # Einstiegsorte wie folgt transformiert S=0, C=1, Q=2
  mutate(age = as.numeric(str_replace(age,",",".")))%>%
  select(survived,pclass,sex,age,embarked))
```


```{r}
titanic.neu <- na.omit(titanic.neu)
```


```{r}
set.seed(137)
inTrain <- createDataPartition(
  y = titanic.neu$survived,
  p = .8,
  list = FALSE)
training <- titanic.neu[ inTrain,]
testing <- titanic.neu[-inTrain,]
```

```{r}
model <- svm(survived ~ ., data = training)
summary(model)
pred <- predict(model, testing[,-1], probability = FALSE)
```
```{r}
(test.results <- cbind(pred, testing))
```


```{r}
library(pROC)
pROC_obj <- roc(test.results$survived, test.results$pred,
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```
2. Was sind die Unterschiede in der Performance der Algorithmen? Finden Sie Erklärungen dafür.

Naive Bayes: 

Der Naive Bayes Algoritmus gibt in meinem Beispiel nur einen AUC-Wert von 0,77 aus. Immernoch gut, aber nicht so hoch wie in der ersten Berechnung mit SVM. 

Dieser Algoritmus berechnet für jedes Kriterium seperat und unabhängig von anderen Kriterien die jeweilige Wahrscheinlichkeit für das Überleben bzw. Sterben der jeweiligen Person(en), auf die das Kriterium zutrifft. Zum Beispiel in der Klasse Alter von 9 Jahren: 

         Alter: 9  Jahre          
0 = tot        0.008130081 
1 = überlebend 0.011627907 

Also sind 1,162% der Überlebenden 9 Jahre alt. 
Hingegen sind nur 0,813% der Toten 9 Jahre alt. 

Diese seperaten Wahrscheinlichkeiten werden in die Berechnung mit einbezogen. 
   
In der Klasse der Einstiegsorte sieht es zum Beispiel wie folgt aus: 


   embarked
Y        0=S          1=C        2=Q
  0 0.79878049 0.13414634 0.06707317
  1 0.65697674 0.31104651 0.03197674
  
Es fällt zum Beispiel auf, dass verhältnismäßig viele Passagiere, die in C zugestiegen sind überlebt haben (31,1% aller Überlebenden kommen aus C, hingegen nur 13,41% der Toten). Bei den anderen Einstiegsorten ist es genau anders herum, dort stiegen mehr (später) Tote als Überlebende ein. Außerdem sind deutlich mehr Passagiere in S eingestiegen als in Q.

Mit dem Algorithmus kann man die verschiedenen Einflussfaktoren viel genauer mit einbeziehen, da er die verschiedenen Wahrscheinlichkeiten unabhängig voneinander mit in die Berechnung einfließen lässt. 

# Naive Bayes

```{r}
my_training <- training %>%
  mutate(survived = as.factor(survived))%>%
  mutate(sex = as.factor(sex))%>%
  mutate(pclass = as.factor(pclass)) %>%
  mutate(age = as.factor(age))%>%
  mutate(embarked = as.factor(embarked))
model <- naiveBayes(survived ~ ., data = my_training)
model
```

```{r}
my_testing <- testing %>%
  mutate(sex = as.factor(sex)) %>%
  mutate(pclass = as.factor(pclass))%>%
  mutate(age = as.factor(age))%>%
  mutate(embarked = as.factor(embarked))
pred <- predict(model, my_testing)
table(pred, my_testing$survived)
```


```{r}
(test.results <- cbind(pred, my_testing))
```

```{r}
test.results <- test.results %>%
  mutate(pred = as.numeric(pred))
pROC_obj <- roc(as.numeric(as.character(test.results$survived)), test.results$pred,
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```
2. Was sind die Unterschiede in der Performance der Algorithmen? Finden Sie Erklärungen dafür.

Decision Tree: 
Der Decision Tree gibt in meinem Beispiel einen AUC-Wert von 0,839 aus. Ähnlich gut wie der SVM-Algorithmus. 

Bei diesem Algorithmus werden nacheinander Entscheidungen getroffen und der konkrete Fall wird anhand dieser Entscheidungen zu einem Kriterium (tot oder überlebend) zugeteilt. Anders als der Naive Bayes Algoritmus bezieht er dabei nicht die einzelnen Wahrscheinlichkeiten unabhängig voneianander mit ein, sondern bezieht diese in einem Entscheidungsprozess nacheinander mit ein. So werden aber ggf. einige Einflussfaktoren außer Acht gelassen. 

Zum Beispiel wird eine Person im unteren Beispiel automatisch als Überlebende eingeteilt, wenn sie weiblich ist und nicht der Klasse 3 angehört (Da 22% aller Überlebender Frauen der Klasse 1 und 2 sind). Und alle Männer über 9,5 Jahren werden automatisch als tot eingruppiert (Da 58% aller Toten Männer über 9,5 Jahre sind). 

Dieser Algorithmus vereinfacht meiner Meinung nach sehr stark (ist dafür jedoch anschaulich). Sein AUC-Wert im Beispiel ist allerdings auch relativ hoch. 


# Decision Tree

```{r}
library(rpart)
library(rpart.plot)
tree<- rpart(survived~., data = training, method = 'class')
rpart.plot(tree)
```
```{r}
dt_results <- predict(tree, testing[,-1], type = 'prob')
head(model.results.dt <- cbind(testing,dt_results),500)
```
```{r}
test.results2 <- test.results %>%
  mutate(pred = ifelse(pred>=0.5,1,0))
table(test.results2$pred, testing$survived)
```


```{r}
pROC_obj <- roc(model.results.dt$survived,model.results.dt$`1`,
            smoothed = TRUE,
            # arguments for ci
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            # arguments for plot
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```

